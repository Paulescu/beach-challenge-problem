# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}\n\nclient<llm> OllamaModel {\n  provider \"openai-generic\"\n  options {\n    base_url \"http://localhost:11434/v1\"\n    model deepseek-r1:7b\n    temperature 0.0\n  }\n}\n",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.202.1\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "solve_problem.baml": "// Defining a data model.\nclass ProblemSolution {\n  reasoning string @description(\"The reasoning process to solve the problem.\")\n  answer float @description(\"The final answer to the problem.\")\n}\n\n// Create a function to solve the problem.\nfunction SolveProblem(problem: string) -> ProblemSolution {\n  // client \"anthropic/claude-3-5-sonnet-20241022\" // Set ANTHROPIC_API_KEY to use this client.\n  // client \"anthropic/claude-sonnet-4-20250514\"\n  client OllamaModel\n  prompt #\"\n    {{ problem }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n\n\n// Test the function with a sample problem\ntest solve_problem {\n  functions [SolveProblem]\n  args {\n    problem #\"\n      Kai and Sofia start at the same point on a beach.\n      Sofia decides to swim directly toward a buoy that's 6.0 km offshore at a 30.0Â° angle from the shoreline.\n      She swims at 2.0 km/hour, but ocean currents push her sideways at 0.5 km/hour perpendicular to her intended direction.\n      Meanwhile, Kai takes his longboard and paddles along the shoreline at 4.0 km/hour for the first hour.\n      After exactly 1 hour, he turns and paddles directly toward Sofia's current position at 3.0 km/hour (slower because he's now fighting waves).\n      If both continue for a total of 2.5 hours from the start, what is the distance between them at the end?\n    \"#\n  }\n\n  // assert the output is not far away from the correct answer\n  @@assert(between_bounds, {{ this.answer > 3.861 and this.answer < 3.864 }})\n}\n",
}

def get_baml_files():
    return _file_map